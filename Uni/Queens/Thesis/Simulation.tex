\chapter{Simulation}

As P--ONE has only deployed the Pathfinder missions thus far, including STRAW and STRAWb, the data used in this thesis is primarily simulated. In particular, the data needs to be usable to test and build a reconstruction algorthim for muon--neutrinos. This means simulating muon tracks. The following section covers the simulation process used to produce the data including the pre--existing IceCube Framework, simulating neutrinos, simulating muons and the detector response. 

\section{IceCube Framework}

The software framework already exists from IceCube, and in order to minimize the amount of new code needed to simulate P--ONE it is simplest to use the IceCube software. In particular, the software documentation is readily available \cite{icetray, icetray_art} and referred to as IceTray. This is meant to be a full framework capable of simulating, reconstructing and analyzing all in one \cite{icetray, icetray_art}. For the purposes of P--ONE, only the simulation subset of the framework is used as it is primarily made using open--source software, and hence can avoid potential proprietary issues.

The bulk of the code is written in C++ with the goal of being modular. This means that rather than writing scripts that call functions or classes that are pre--existing, the code is designed so that there is a single steering script that calls modules to run tasks including the simulation of muons or neutrinos, and including geometry files. Modules can be added by users as well to then be included in the steering scripts. The code has also been wrapped using Python so that modules can be reached via python scripts, and hence steering scripts can be written in Python. For this reason, Python is the language of choice for the purposes of this work.

Due to the nature of data collected by neutrino telescopes, the Icetray framework was developed to handle working with photon tables in a manageable manner. Photon propogation and simulation at reconstruction time is an intensive process, and for real events is avoided by using simulations done apriori to construct tables that can be used at event analysis time \cite{icetray_art}. The tables generated must be massive for this reason, and the Icetray framework works around this issue by allowing each module to work independently of the others with output queues so that the underlying topology of the modules is generally non-linear and can be quite complex. As the data needed to be simulated for this work, the photons were simulated as well, though tables may be used in the future. A more detailed explaination of Icetray can be found here \cite{icetray_art}.

\section{Simulating Neutrinos}

The Icetray sofware used to generate neutrinos is the very aptly named Neutrino--Generator (NuGen) \cite{icetray, icetray_art}. This is code written in IceTray based off of the All Neutrino Interaction Generator (ANIS), a high energy neutrino generator used for neutrino telescopes developed originally for AMANDA \cite{lepton_inj}. NuGen uses a cylinder in which the events are generated to inject the neutrinos into the detection volume \cite{sim_present}. The main purpose of the cylinder is to provide the user with control over where the neutrinos are generated without exact positions. As a neutrino telescope primarily aims to detect neutrinos that have traveled through the earth, NuGen uses an Earth model to measure the density to use when computing the interaction probability. As described in \cite{sim_present}, NuGen computes the track length inside the earth and inside the detection volume seperately and then computes step--wise the path of the neutrino checking each step if it interacts with the earth using the depth and cross--section. If ever an interaction occurs, it will decide the interaction randomly and produces secondaries. These are then propogated until they reach the detector volume. A propogation probability and interaction probability are computed of the interaction, and then the neutrino is weighted for use when predicting fluxes. This weight is defined as
\begin{equation}
  w_{i} = \frac{OneWeight_{i}}{NEvents}\times \frac{d\Phi_{\nu}(E_{\nu})}{dE_{\nu}} \, ,
\end{equation}
where
\begin{equation}\label{eq:one_weight}
  OneWeight = \left(\frac{P_{\text{int}}}{E^{-\gamma}}\right)\cdot \int_{E_{\text{min}}}^{E_{\text{max}}}E^{-\gamma}dE\cdot Area\cdot \Omega \cdot T[\text{Gev}\cdot cm^{2}\cdot s\cdot sr]
\end{equation}.
In Equation \ref{eq:one_weight}, $P_{\text{int}}$ is the total interaction probability weight, $E^{-\gamma}$ is the neutrino generation energy spectrum shape, $E_{\text{min}}$ and $E_{\text{max}}$ is the minimum and maximum generation energy of neutrinos, $Area$ is the generation area, $\Omega$ is the solid angle and $T$ is 1 second and the timescale.

The lepton propogation is carried out by PROPOSAL, more software used by IceCube. PROPOSAL accounts for stochastic energy losses due to ionization, positron-electron pair production, bremsstrahlung, photo-nuclear interactions and decay \cite{sim_present}. The photon propogation is handled by CLSim, which accounts for optical properties of the medium and absorption/scattering interactions. This can be done in either a parallel or series manner by using either GPUs or CPUs respectively. 

\section{Simulating Muons}

The module used to generate muons is the MuonGun that exists in GEANT4. This can be used to inject muons based on some sampling surface dependent upon a given flux model \cite{icetray}. Muon Gun is versatile as it can be easily modified to produce muons using a variety of sampling surfaces, and can even be modified to be energy dependent \cite{icetray}. Muon Gun works by drawing samples from a parameterization/fit of the atmospheric muon flux \cite{icetray,muon_param}, and for this work the flux model used is the one created by IceCube \cite{icetray} where fits are made to CORSIKA \cite{corsika} simulations with SIBYLL \cite{sibyll} wieghted to the spectrum by Hoerandel \cite{hoerandel}. Understanding this requires understanding the muon background source.

\subsection{Cosmic Ray Muons}

As discussed in Section \ref{subsec:atmos}, neutrinos can be produced in the atmosphere from cosmic ray interactions. Another byproduct of these interaction cascades are muons \cite{corsika, sibyll}, which can become a background in neutrino telescopes and require characterization. To understand this background source at the detector level, the muon flux needs to be tracked back to the source of the atmosphere and the cosmic ray flux. The cosmic ray flux used to develop the parameterized forms found in \cite{muon_flux} and the fits in \cite{icecube} is based off of the specturm described by Hoerandel in \cite{hoerandel}.

Predicting the cosmic ray flux is no walk in the park. Ignoring theoretical models to predict the sources and build a model that way, which is still covered in \cite{hoerandel} but of no real consequence for the purposes of this text, Hoerandel introduces the \textit{poly--gonato} model. This is the method used to fit the observed energy distribution of cosmic rays for different types of cosmic rays. These range from protons to heavier nuclei like iron \cite{hoerandel}. This can accurately describe the observed energy spectrum and mass composition in the energy range from 10 GeV to atleast 100 PeV. In particular, this model accurately describes the first ``knee'' at 4.5 PeV in the energy spectrum with subsequent cut-offs for individual elements, starting with protons, and the second ``knee'' at 400 PeV with the end of the galactic component \cite{hoerandel}. 

With the cosmic ray flux modeled, the interactions to produce the showers with the muons in them still need to be simulated. The softwares used to do these simulations are Cosmic Ray Simulations for Kascade (CORSIKA) and Sibyll (atmospheric cascade event generator). 
\subsection{Flux Model}

 This is parameterized in the same manner as described in \cite{muon_flux}; it depends on the water depth ($h$), zenith angle ($\theta$), multiplicity, and energy. In particular, the energy spectrum of single muons is described by
\begin{equation}
  \frac{dN}{d(\log_{10}E_{\mu})} = G\cdot E_{\mu}e^{\beta X(1 - \gamma)}\left[E_{\mu} + \epsilon(1 - e^{-\beta X})\right]^{-\gamma}\, ,
\end{equation}
where there are multiple fit parameters described more in \cite{muon_flux}. The energy loss due to water interactions also have to be added and are also discussed in \cite{muon_flux}. These parameterizations are great for fast generation of muons \cite{muon_flux}, which is important for understanding the background of cosmic ray muons common in most neutrino telescopes \cite{icecube, antares, amanda, pone, muon_flux}. 

Do we talk about Muon Gun or Cosmic Muons? Currently only Cosmic Muons are being used but both could be used.

\section{Detector Response}

The choice of geometry is incredibly important, as varying the position and number of detectors can, as one would expect, result in large changes in the performance of the detecor (\textbf{WHERE TO CITE THIS FROM?}). The current proposed first stage of P--ONE is to be a pair of nested circles with the inner containing three strings and the outer containing 7 \cite{pone}, as we can see in Figure \ref{fig:pone_geo}. The simulated geometry is based off of this first design and held in a ``.gcd'' file which is used by IceTray \cite{icetray}. \textbf{GET IMAGE OF GCD HERE SOMEHOW}. If we wish to see how the potential detector performance is affected by varying the geometry, we can change this geometry file and measure parameters such as the effective area to see how well it compares.

One of the most useful and widely used methods of measuring a neutrino detectors performance at a glance is the effective area. For a given particle of interest with some flux, the effective area is defined as the area of the detector scaled by the efficiency of the detector in measuring this particle \cite{2010icecube}. Another way of phrasing this is that the effective area is that which detects perfectly the particles entering it for a given number of detections. Computing the effective area is non-trivial, as it is particle, flavour, energy, and direction dependent. 

This has to include the detector geometry (GCD) files, the DOMs, and efficiency...?

