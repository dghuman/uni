\documentclass[10pt]{article}
\usepackage[]{ragged2e}
\usepackage{fancyhdr,amsmath,amsthm,amssymb,bbm,graphicx,array,bm,tensor,braket,mathtools,tensor}
\usepackage{mathtools,tkz-euclide}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper,left=25mm,right=25mm]{geometry}

\setlength{\parskip}{1em}
\setlength{\parindent}{0em}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}

\DeclareMathOperator{\Ima}{Im}

\linespread{1.25}
\pagestyle{fancy}
\fancyhf{}
\lhead{PHYS 921 $|$  Assignment 1}

\rhead{Dilraj Ghuman $|$ 20191345}

\begin{document}

\textbf{\Large 1. Dimensional Analysis}

\textbf{Q1} \textit{Derive the relationship between the period of a pendulum, gravitational accelera-
tion, and the pendulum’s relevant physical quantities.}

Simple exercise of comparing dimensions. In particular we know that period, $P \sim [T]$, must be related to the two physical quantities of gravity, $g \sim [L][T]^{-2}$, and length of the string, $\ell \sim [L]$. Thus, supposing some constant, $\alpha$, we can suppose

\begin{align*}
  P & \sim \alpha g^{a}\ell^{b} \sim \alpha\left([L][T]^{-2}\right)^{a}[L]^{b} \\
  [T] & \sim \alpha [L]^{a + c}[T]^{-2a} 
\end{align*}
\[
\implies a = -\frac{1}{2} \hspace{2em} \implies \hspace{2em} b = \frac{1}{2}
\]
and thus, $P \sim \alpha\sqrt{\frac{\ell}{g}}$.

\textbf{Q2} \textit{Beginning only with the knowledge that a right triangle’s area is some function of
the length of its hypotenuse and a non-right adjoining angle, prove the Pythagorean
theorem using dimensional analysis. (Do not use any trigonometric identities. You
may use basic geometry. The standard solution involves drawing a certain line that
splits the right triangle into smaller right triangles.)}

We start by splitting our right angle triangle into two parts:

\begin{center}
  \begin{tikzpicture}[scale=5]
    % Define Edges
    \coordinate (A) at (0,0);
    \coordinate (B) at (1,0);
    \coordinate (C) at (0,1);
    \coordinate (D) at (0.5,0.5);
    % Cycle through
    \draw (A)--(B)--(C)--cycle;
    % Bisection
    \draw (0,0) -- (0.5,0.5);
    % Labels
    \tkzLabelSegment[below=2pt](A,B){\textbf{a}}
    \tkzLabelSegment[left=2pt](A,C){\textbf{b}}
    \tkzLabelSegment[above right=2pt](B,C){\textbf{c}}
    % Label Sections
    \node at (0.5,0.25) {\textbf{(1)}};
    \node at (0.25,0.5) {\textbf{(2)}};
    % Angles
    \tkzMarkRightAngle[fill=none,size=0.1,opacity=.4](C,A,B)
    \tkzMarkAngle[fill=none,size=0.3,opacity=.4](C,B,A)
    \tkzMarkAngle[fill=none,size=0.3,opacity=.4](D,A,C)
    \tkzLabelAngle[pos = 0.37](C,B,A){\(\theta\)}
    \tkzLabelAngle[pos = 0.37](D,A,C){\(\theta\)}
  \end{tikzpicture}
\end{center}

Note by geometric properties, the two smaller triangles (\textbf{(1)} and \textbf{(2)}) are actually similar (infact, all 3 are similar!). Thus, as is shown with $\theta$ being consistent with them both, we can apply our rule of area:

\[
\begin{aligned}
  A_{(0)} & = A_{(1)} + A_{(2)} \\
  c^{2}f(\theta) & = a^{2}f(\theta) + b^{2}f(\theta) \\
  \Aboxed{c^{2} & = a^{2} + b^{2}}
\end{aligned}
\]

\textbf{Q3} \textit{Derive the relationship between the number of rowers in a boat, and the boat’s speed. Assume each rower contributes the same power to the boat’s motion. (Hint:The drag force the rowers are pulling against is given by $F \sim \rho A v^{2}$, where $\rho$ is the density of water and $A$ is the area of a boat. Archimedes’ principle of displacement should inform you as to how $A$ changes with the number of rowers.)}

First, we need to relate the number of rowers with the area of the boat, $A$. This effectively reduces to the square-cubed law; the depth of the boat scales with $n$ so the area must go as $a^{\frac{2}{3}}$. Now, the problem is straight forward if we assume maximum velocity of the boat:
\[
\begin{aligned}
  F & \sim \rho Av^{2} \\
  P & \sim \rho a^{\frac{2}{3}}v^{3} \\
  n & \sim \rho a^{\frac{2}{3}}v^{3} \\
  \Aboxed{v & \sim n^{\frac{1}{9}}\rho^{-\frac{1}{3}}}
\end{aligned}
\]

\textbf{Q4} \textit{Srednicki 12.3}

This is simple; we know that distance is inversely proportional to mass in natural units, so we can approximate $r$ as such:
\[ r \sim \frac{1}{m} = \frac{1}{0.938\, \text{GeV}}\cdot 2\times10^{-14}\,\text{Gev}\cdot\text{cm} = 2.132\times10^{-14}\,\text{cm} \]
as required.

\textbf{\Large 2. Ising Model}

\textbf{Q1} \textit{The nearest neighbor Ising model has a certain “$Z_{2}$ symmetry” sometimes called the Ising model time symmetry. Prove that the nearest neighbor Ising model free energy density is invariant under the replacement $B \to -B$. (Note that the free energy density here is defined for a very large or infinite Ising model system). Say as plainly as you can why the nearest neighbor Ising model has this symmetry.}

We first look at the energy equation to see how it transforms when we $B \to -B$:
\[
E \to E' = -(-B)\sum_{i}s_{i} - J\sum_{\langle ij\rangle}s_{i}s_{j} = -B\sum_{i}(-s_{i}) - J\sum_{\langle ij\rangle}s_{i}s_{j} 
\]
\[
E\to E' = s_{i} \to -s_{i} \, .
\]

So, in our free energy equation, we see
\[
F \to F' = -T\log Z' = -T\log\left(\sum_{\{s_{i}\}}e^{-\beta E'}\right)
\]
but we know that
\[
\sum_{\{s_{i}\}}f(s_{i}) = \sum_{\{s_{i}\}}f(-s_{i})
\]
so it must be true that $F \to F' = F$, and hence the free energy is invariant under this transformation. Physically, this is saying that we can flip the magnetic field but the average free energy in the system will remain unchanged. This makes sense, we don't add energy by choosing a different direction for the magnetic field!

\textbf{Q2} \textit{The nearest neighbor Ising model has an additional symmetry for $B = 0$. For this case of zero external magnetic field, there is an additional symmetry of the free energy density under the replacement $J \to -J$, so long as the Ising model is defined over a cubic [3d] (or square [2d] or linear [1d]) tiled lattice. To prove this, you will want to first define interlocking sub-lattices of the Ising model, $a$ and $b$, such that $a$'s have only $b$'s adjacent to them, and $b$'s have only $a$'s adjacent to them. For example for the linear case this is easy, every other site is labeled $a$, the rest $b$. Say as plainly as you can why the nearest neighbor Ising model has this symmetry, only when $B = 0$.}

We can show this transformation is equivalent to another, just like above. In particular, we start by partitioning our set into the $a$'s and $b$'s. In particular, it is easy to imagine we can define these sub-lattices, by first starting with the linear case; we just alternate between $a$'s and $b$'s. For the 2D case, we can imagine alternating between each layer and building up the sheet. For the 3D case we repeat this method to produce a 3D lattice.

Now that we know these sub-lattices do indeed exist, atleast for the 1, 2 and 3 dimensional cases, we can move onto the transformation. To start, we note that since the $J$ coupling only pairs nearest neighbours, we can rewrite the energy as
\[
E = -J\sum_{\langle ij\rangle}s_{i}s_{j} = -J\sum_{\langle ij\rangle}s^{A}_{i}s^{B}_{j}
\]
where $s^{A}_{i}$ is in the $a$'s and $s^{B}_{j}$ is in the $b$'s. In this case, as in \textbf{Q1}, we can apply the transformation and see what is equivalent
\[
E \to E' = -(-J)\sum_{\langle ij\rangle}s^{A}_{i}s^{B}_{j} = -J\sum_{\langle ij\rangle}(-s^{A}_{i})s^{B}_{j} = -J\sum_{\langle ij\rangle}s^{A}_{i}(-s^{B}_{j}) \,.
\]
Thus, we see $J \to -J$ is the same as $\{s^{A}\} \to \{-s^{A}\}$ or $\{s^{B}\} \to \{-s^{B}\}$. You'll note that we set $B = 0$, and this is because these transformations aren't equivalent if we don't set it so. Noting this, we use the same rule we had above as the free energy will still be a sum over all set of spins, and since this includes the $a$'s, we can conclude the transformation will be invariant!

\textbf{Q3} \textit{The infinite range Ising Model. We will consider a variant of the Ising model, where all spins interact equally with all other spins. Then the energy (a.k.a. Hamiltonian) of this system composed of N Ising sites can be given by}
\[
E = -B\sum_{i}s_{i} - \frac{1}{2N}\sum_{ij}s_{i}s_{j}\, ,
\] 
\textit{where here notice that the sum over interacting spins runs over all pairs in the lattice.}

\textbf{(a)} \textit{Why must the interaction term be normalized by a factor of $\frac{1}{2N}$? (Consider especially the case of an infinite Ising model.)}

First, we notice how the Magnetic field term changes. In particular, we consider the fringe (edge) case when all of our spins are aligned, and for simplicity suppose the alignment is $s_{i} = +1$. In this case, for the first term in the energy ($E$), we see
\[ -B\sum_{i}^{N}s_{i} = -B\sum_{i}^{N}(1) = -NB \, .\]
So, this term goes as $N$. We want our coupling term to be the same order, since the free energy density will then multiply this by $\frac{1}{N}$ and will be normalized in the infinite sites limit. To see how we normalize this term, we look at what the coupling term becomes in the fringe case,
\[ -\sum_{i,j}^{N}s_{i}s_{j} = -\sum_{i,j}^{N}(1)(1) = -N^{2}\, .\]
There are two things we can do to this:
\begin{itemize}
\item The self-interaction terms don't actually matter; we don't care about the $i=j$ terms, and there are $N$ of them.
\item The interaction $s_{i}$ with $s_{j}$ is the same as $s_{j}$ with $s_{i}$, so we double counted and need to divide by $2$.
\end{itemize}
This means the actual sum goes as $\sim\frac{N^{2} - N}{2}$, which still diverges quadratically for the infinite sites case. Thus, we need to normalize this by dividing by $N$, and hence our coeffecient becomes $\frac{1}{2N}$.

\textbf{(b)} \textit{The partition function for this model can actually be calculated exactly, using the saddle-point method and a classic ``complete the square'' inside a Gaussian integral trick. First, the trick. Show that the exponential (a.k.a. Boltzmann) function in the partition function can be re-written as follows.}
\[
\exp[-\beta E] = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2} + \sum_{i}\beta(y + B)s_{i}\right]\, .
\]
\textit{Hint: Use the Gaussian integral $\int dxe^{-ax^{2}} = \sqrt{\frac{\pi}{a}}$ and complete the square under the integral.}

We start with the RHS and prove it is indeed the LHS,

\begin{align*}
  \text{RHS} & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2} + \sum_{i}\beta(y + B)s_{i}\right]\\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2} + y\beta\sum_{i}s_{i} + B\beta\sum_{i}s_{i}\right]\\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta}{2}\left(y^{2} - \frac{2}{N}y\sum_{i}s_{i} - \frac{2B}{N}\sum_{i}s_{i}\right)\right] \\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta}{2}\left(\left(y - \frac{\sum_{i}s_{i}}{N}\right)^{2} - \frac{2B}{N}\sum_{i} - \frac{1}{N^{2}}\sum_{i}s_{i}s_{j}\right)\right]\\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta}{2}\left(y - \frac{\sum_{i}s_{i}}{N}\right)^{2}\right]\exp\left[ -\beta\left(\underbrace{B\sum_{i} - \frac{1}{2N}\sum_{i}s_{i}s_{j}}_{E}\right)\right]\\
  & = \sqrt{\frac{N\beta}{2\pi}}\sqrt{\frac{2\pi}{N\beta}}e^{-\beta E} \\
  & = e^{-\beta E} \\
  & = \text{LHS} \, .
\end{align*}

\textbf{(c)} \textit{Starting with the above relation and also using the expression for the $J = 0$ partition function derived in the 921 Notes, show further that}
\[
Z = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp[-N\beta A(y)]\, , \hspace{2em} A(y) = -\beta^{-1}\ln\left(2\cosh[\beta(y+B)]\right) + \frac{y^{2}}{2}\, .
\]

This is an algebra problem, like the one before,
\begin{align*}
  Z & = \sum_{\{s_{i}\}}e^{-\beta E} = \sum_{\{s_{i}\}}\left(\sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2} + \sum_{i}\beta(y + B)s_{i}\right]\right) \\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2}\right]\sum_{\{s_{i}\}}\exp\left[\sum_{i}\beta(y + B)s_{i}\right] \\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2}\right]\left(2\cosh(\beta(y + B))\right)^{N} \\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2}\right]\exp\left[N\ln\left(2\cosh(\beta(y + B))\right)\right] \\
  & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-\frac{N\beta y^{2}}{2} + N\ln\left(2\cosh(\beta(y + B))\right)\right] \\
  \Aboxed{Z & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-N\beta\left(\underbrace{\frac{y^{2}}{2} - \beta^{-1}\ln\left(2\cosh[\beta(y+B)]\right)}_{A(y)}\right)\right]}\, .
\end{align*}

\textbf{(d)} \textit{We can now use the saddle point method to determine the approximate solution for the partition function, by maximizing the above exponential (which means minimizing our function $A(y))$. Solve for the partition function, and call the value of $y$ that minimizes $A(y)$, $y_{0}$.}

To minimize $A(y)$, we need only take the derivative,
\begin{align*}
  0 & = \frac{\partial A(y)}{\partial y} = -\frac{1}{\beta}\frac{2\sinh\left(\beta(y + B)\right)\beta}{2\cosh\left(\beta(y + B)\right)} + y\\
  & = -\tanh\left(\beta(y + B)\right) + y \\
  \Aboxed{\implies & y_{0} = \tanh\left(\beta(y_{0} + B)\right) }\, .
\end{align*}
So, we know any $y_{0}$ that satisfies this condition will be our approximate solution.

\textbf{(e)} \textit{Show that $y_{0}$ is actually the magnetization of this system, (which can be compared to Eq.(1.11) in the Tong notes). Do this by framing the parition function in the form $Z = e^{-N\beta f}$ , where $f$ is the free energy per spin. Then the equilibrium magnetization is given by $-\frac{\partial f}{\partial B} = m$ (see e.g. Eq.(1.6) of Tong). Why can we sensibly think about an average magnetization for this infinite-range interacting system, that looks nearly identical to the magnetization for the nearest neighbor Ising model?}

We do this by comparing the form $Z = e^{-N\beta f}$ with what we did in \textbf{(d)},
\begin{align*}
  e^{-N\beta f} & = \sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-N\beta A(y,B)\right] \\
  \implies f & = -\frac{1}{N\beta}\ln\left[\sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-N\beta A(y,B)\right]\right] \\
  \implies m & = -\frac{\partial f}{\partial B} \\
  & = \frac{1}{N\beta}\frac{\partial}{\partial B}\ln\left[\sqrt{\frac{N\beta}{2\pi}}\int_{-\infty}^{\infty}dy\exp\left[-N\beta A(y,B)\right]\right] \\
  & = \frac{1}{N\beta}\frac{\int_{-\infty}^{\infty}dy(-N\beta)\exp\left[-N\beta A(y,B)\right]\frac{\partial A}{\partial B}}{\int_{-\infty}^{\infty}dy\exp\left[-N\beta A(y,B)\right]} \\
  & = -\frac{\partial A(y, B)}{\partial B} \\
  & = -\frac{\partial}{\partial B}\left(\frac{y^{2}}{2} - \beta^{-1}\ln\left(2\cosh[\beta(y+B)]\right)\right) \\
  \Aboxed{m  & = \tanh\left(\beta(y+B)\right)}\, .
\end{align*}
As we can see, our $m$ is comparable to $y$ and hence will have the same solution of $y_{0}$. 

Even though the $n^{\text{th}}$ spin will interact with an infinite number of neighbours, we can imagine that all of those infinite interactions are being averaged into an effective nearest neighbour interaction. This effective interaction will then mimic the usual nearest neighbour interaction, and so  it isn't so weird that the magnetization looks like the usual Ising Model!

\textbf{\Large 3. Quantum Field Theory Intro}

\textbf{Q1} \textit{Srednicki 1.1: Show that the Dirac matrices must be even dimensional.}

We know that $(\beta^{2})_{ab} = \delta_{ab}$, and thus
\[
1 = \text{det}(\beta^{2}) = \left(\text{det}(\beta)\right) \implies \text{det}(\beta) = \pm 1\, .
\]
Since, in diagonal form, the determinant is the product of the eigenvalues, we know $\lambda_{i} = \pm 1$. Next, notice that the trace can be found using an identity and the anti-commutation of $alpha^{i}$ with $\beta$:
\begin{align*}
  \text{Tr}(\alpha^{i}\alpha^{i}\beta) & = \text{Tr}(\alpha^{i}(-\beta\alpha^{i}))\\
  \text{Tr}(\alpha^{i}\beta\alpha^{i}) & = -\text{Tr}(\alpha^{i}\beta\alpha^{i})\, .
\end{align*}

The final equality comes from the permutation identity of traces. This result tells us that $\text{Tr}(\beta) = 0$. Thus, we can conclude that the dimension of $\beta$ must be even. Notice we can do exactly the same game for the trace with $\text{Tr}(\beta\beta\alpha^{i})$, and so all we need to do now is show that the eigenvalues are also restricted to $\pm 1$. Notice,
\[
\{\alpha^{k}, \alpha^{k}\}_{ab} = 2\delta^{kk}\delta_{ab} \, \implies \, 2(\alpha^{kk})^{2}_{ab} = 2\delta_{ab} \, \implies \, \text{det}((\alpha^{kk})^{2}_{ab}) = \text{det}(delta_{ab}) 
\]

thus we can play the same game as we did initially and get that the eigenvalues must be $\pm 1$. Therefore we have shown that the Dirac matrices must be even in dimension.

\textbf{Q2} \textit{Srednicki 2.1: Verify that eq 2.8 follows from eq 2.3.}

Starting with equation 2.3, we can plug in the infinitesimal Lorentz transform that is equation 2.7,
\begin{align*}
  g_{\mu\nu}\tensor{\Lambda}{^{\mu}_{\rho}}\tensor{\Lambda}{^{\nu}_{\sigma}} & = g_{\rho\sigma} \\
  g_{\mu\nu}\left(\tensor{\delta}{^{\mu}_{\rho}} + \tensor{\delta w}{^{\mu}_{\rho}}\right)\left(\tensor{\delta}{^{\nu}_{\sigma}} + \tensor{\delta w}{^{\nu}_{\sigma}}\right) & = g_{\rho\sigma} \\
  g_{\mu\nu}\left(\tensor{\delta}{^\mu_\rho}\tensor{\delta}{^\nu_\sigma} + \tensor{\delta}{^\mu_\rho}\tensor{\delta w}{^\nu_\sigma} + \tensor{\delta w}{^\mu_\rho}\tensor{\delta}{^\nu_\sigma} + \tensor{\delta w}{^\mu_\rho}\tensor{\delta w}{^\nu_\sigma}\right) & = g_{\rho\sigma}\\
  \tensor{\delta}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}} + \tensor{\delta}{^\mu_\rho}\tensor{\delta w}{_{\mu\sigma}} + \tensor{\delta w}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}} + \underbrace{\tensor{\delta w}{^\mu_\rho}\tensor{\delta w}{_{\mu\sigma}}}_{0} & = g_{\rho\sigma}\\
  \tensor{\delta}{^\mu_\rho}\tensor{\delta w}{_{\mu\sigma}} + \tensor{\delta w}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}}  & = g_{\rho\sigma} - \tensor{\delta}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}} \\
  g^{\rho\sigma}\left(\tensor{\delta}{^\mu_\rho}\tensor{\delta w}{_{\mu\sigma}} + \tensor{\delta w}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}}\right)  & = 1 - \tensor{\delta}{^\mu_\rho}\tensor{\delta}{_{\mu\sigma}}g^{\rho\sigma} \\
  \tensor{\delta}{^{\mu\sigma}}\tensor{\delta w}{_{\mu\sigma}} + \tensor{\delta w}{^{\mu\sigma}}\tensor{\delta}{_{\mu\sigma}}  & = 1 - \tensor{\delta}{^{\mu\sigma}}\tensor{\delta}{_{\mu\sigma}} \\
  \tensor{\delta}{^{\mu\sigma}}\tensor{\delta w}{_{\mu\sigma}} & = -\tensor{\delta w}{^{\mu\sigma}}\tensor{\delta}{_{\mu\sigma}}\\
  \Aboxed{\tensor{\delta w}{_{\mu\sigma}} & = -\tensor{\delta w}{_{\mu\sigma}}}\, .
\end{align*}

\textit{Srednicki 2.6: Verify that eq 2.19 follows from eq 2.18.}

This is easy enough, we just need to compute the components of equation 2.18 using the definitions $J_{i} = \frac{1}{2}\varepsilon_{ijk}M^{jk}$, $K_{i} = M^{i0}$ and $P^{\mu} = (H, P^{i})$. In particular, notice:
\[
  [J_{i},H] = -[H, J_{i}] = -[P^{0},\frac{1}{2}\varepsilon_{ijk}M^{jk}] = -\frac{1}{2}\varepsilon_{ijk}[P^{0},M^{jk}] = -\frac{1}{2}\varepsilon_{ijk}\left(i\hbar(g^{0k}P^{j} - g^{0j}P^{k})\right) = \boxed{0} \, ,
\]
\[
  [J_{i}, P_{j}] = -[P_{j},J_{i}] = -[P_{j},\frac{1}{2}\varepsilon_{ilk}M^{lk}] = -\frac{1}{2}\varepsilon_{ilk}[P_{j},M^{lk}] = -\frac{1}{2}g_{jh}\varepsilon_{ilk}\left(i\hbar(g^{hk}P^{l} - g^{hl}P^{k})\right) = \boxed{i\hbar\varepsilon_{ijk}P_{k}}\, ,
\]
\[
  [K_{i}, H] = -[H, K_{i}] = -[P^{0}, M^{i0}] = -i\hbar\left(g^{00}P^{i} - g^{0i}P^{0}\right) = \boxed{i\hbar P_{i}}\, ,
  \]
  \[
[K_{i}, P_{j}] = -[P_{j}, K_{i}] = -g_{jh}[P^{h}, M^{i0}] = -g_{jh}i\hbar\left(g^{h0}P^{i} - g^{hi}P^{0}\right) = i\hbar\tensor{\delta}{_{ij}}P^{0} = \boxed{i\hbar\tensor{\delta}{_{ij}}H} \, .
\]

\textit{Srednicki 2.7: What property should be attributed to the translation operator $T(a)$ that could be used to prove equation 2.2.}

This is the additive property. In particular, we can recall that if $A$ and $B$ are matrices (or operators), then $e^{A}e^{B} = e^{A + B}$ if and only if $[A,B] = 0$. Applying this to $P^{\mu}$ and it's components yeilds our result. Note that the identity can easily be proven by using taylor expansion and then trying to add the terms (we effectively get that we need to move terms past each other).

\textit{Srednicki 2.8: a) Let $\Lambda = 1 + \delta w$ in eq 2.26, and show equation 2.29 and 2.30 are true.}

We first start by recalling that $U(1 + \delta w) = I + \frac{i}{2\hbar}\delta w_{\mu\nu}M^{\mu\nu}$, and thus we begin:
\begin{align*}
  U(\Lambda)^{-1}\varphi(x)U(\Lambda) & = \varphi(\Lambda^{-1}x) \\
  \left(I - \frac{i}{2\hbar}\delta w_{\mu\nu}M^{\mu\nu}\right)\varphi(x)\left(I + \frac{i}{2\hbar}\delta w_{\rho\sigma}M^{\rho\sigma}\right) & = \varphi(\Lambda^{-1}x)\\
  \varphi(x) - \frac{i}{2\hbar}\delta w_{\mu\nu}M^{\mu\nu}\varphi(x) + \varphi(x)\frac{i}{2\hbar}\delta w_{\rho\sigma}M^{\rho\sigma} + \underbrace{O(\delta w^{2})}_{\sim 0} & = \varphi(\Lambda^{-1}x)\\
  \varphi(x) + \frac{i}{2\hbar}\delta w_{\mu\nu}[\varphi(x),M^{\mu\nu}] & = \varphi(\Lambda^{-1}x)\\
  \frac{i}{2\hbar}\delta w_{\mu\nu}[\varphi(x),M^{\mu\nu}] & = \varphi((\tensor{\delta}{^{\rho}_{\sigma}} + \tensor{\delta w}{^{\rho}_{\sigma}})x^{\sigma}) - varphi(x)\\
  \frac{i}{2\hbar}\delta w_{\mu\nu}[\varphi(x),M^{\mu\nu}] & = \varphi(x) +\tensor{\delta w}{^{\rho}_{\sigma}}x^{\sigma}\partial_{rho}\varphi  - varphi(x)\\
  \frac{i}{2\hbar}\delta w_{\mu\nu}[\varphi(x),M^{\mu\nu}] & = \frac{1}{2}\tensor{\delta w}{^{\rho}_{\sigma}}\left(x^{\sigma}\partial^{\rho} - x^{\rho}\partial^{\sigma}\right)\varphi\\
       \Aboxed{[\varphi(x),M^{\mu\nu}] & = \left(x^{\mu}\partial^{\nu} - x^{\nu}\partial^{\mu}\right)\varphi} .\\
\end{align*}

\textit{b) Show that $[[\varphi(x), M^{\mu\nu}], M^{\rho\sigma}] = \mathcal{L}^{\mu\nu}\mathcal{L}^{\rho\sigma}\varphi(x)$. }

So we start with the LHS and work towards the RHS. Notice first,
\[
  [[\varphi(x), M^{\mu\nu}],M^{\rho,\sigma}] = [\mathcal{L}^{\mu\nu}\varphi(x), M^{\rho\sigma}]\, .
\]
  
Well, notice that

\begin{align*}
  [\mathcal{L}^{\mu\nu}, M^{\rho\sigma}] & = \mathcal{L}^{\mu\nu}M^{\rho\sigma} - M^{\rho\sigma}\mathcal{L}^{\mu\nu} \\
  & = \frac{\hbar}{i}\left(x^{\mu}\partial^{\nu} - x^{\nu}\partial^{\mu}\right)M^{\rho\sigma} - M^{\rho\sigma}\frac{\hbar}{i}\left(x^{\mu}\partial^{\nu} - x^{\nu}\partial^{\mu}\right)\, ,
\end{align*}
and it looks like $[x^{\mu}\partial^{\nu},M^{\rho\sigma}] = 0$, so $[\mathcal{L}^{\mu\nu}, M^{\rho\sigma}] = 0$. Thus,

\begin{align*}
  [[\varphi(x), M^{\mu\nu}],M^{\rho,\sigma}] & = [\mathcal{L}^{\mu\nu}\varphi(x), M^{\rho\sigma}] \\
  & = \mathcal{L}^{\mu\nu}[\varphi(x), M^{\rho\sigma}]\\
  & = \boxed{\mathcal{L}^{\mu\nu}\mathcal{L}^{\rho\sigma}\varphi(x)}\, .
\end{align*}

\textit{c) Prove the Jacobi Identity.}

Personally I think this isn't particularly useful to prove, since it follows from the definition of the commutator (or any bilinear algebra braket), but I guess it needs to be done. So, expand and cancel:
\[
  [[A,B],C] = [A,B]C - C[A,B] = (AB - BA)C - C(AB - BA) = ABC - BAC - CAB + CBA
  \]
\[
  [[B,C],A] = [B,C]A - A[B,C] = (BC - CB)A - A(BC - CB) = BCA - CBA - ABC + ACB
\]
\[
  [[C,A],B] = [C,A]B - B[C,A] = (CA - AC)B - B(CA - AC) = CAB - ACB - BCA + BAC
\]
and we notice that everything cancels.

\textit{d) Use your results from (b) and (c) to get eq 2.31. }

So, we start from the LHS and go from there:
\begin{align*}
  [\phi(x), [M^{\mu\nu},M^{\rho\sigma}]] & = -[[M^{\mu\nu},M^{\rho\sigma}],\phi(x)] \\
  & = [[M^{\rho\sigma},\phi(x)], M^{\mu\nu}] + [[\phi(x),M^{\mu\nu}], M^{\rho\sigma}] \\
  & = -[[\phi(x),M^{\rho\sigma}], M^{\mu\nu}] + [[\phi(x),M^{\mu\nu}], M^{\rho\sigma}] \\
  & = -\mathcal{L}^{\rho\sigma}\mathcal{L}^{\mu\nu}\phi(x) + \mathcal{L}^{\mu\nu}\mathcal{L}^{\rho\sigma}\phi(x) \\
  & = \boxed{\left(\mathcal{L}^{\mu\nu}\mathcal{L}^{\rho\sigma}-\mathcal{L}^{\rho\sigma}\mathcal{L}^{\mu\nu}\right)\phi(x)}\, .
\end{align*}

\textit{e) Simplify the right-hand side of eq 2.31 as much as possible. }

\textit{f) ...}


\textbf{\Large 4. Quantizing Fields}

\textbf{Q1} \textit{Srednicki 3.1: Derive eq. 3.29 from eqs. 3.21, 3.24, and 3.28.}

We do these by brute force (plug and solve):

\begin{align*}
  [a(\bm{k}), a(\bm{k'})] & = \left[\int d^{3}xe^{-ikx}(i\partial_{0}\varphi(x) + \omega\varphi(x)),\int d^{3}x'e^{-ik'x'}(i\partial_{0}\varphi(x') + \omega\varphi(x'))\right] \\
  & = \int \int d^{3}x\, d^{3}x' e^{-ikx}e^{-ik'x'}\left[i\underbrace{\partial_{0}\varphi(x)}_{\Pi(x)} + \omega\varphi(x), i\underbrace{\partial_{0}\varphi(x')}_{\Pi(x')} + \omega\varphi(x')\right] \\
  & = \int \int d^{3}x\, d^{3}x' e^{-ikx}e^{-ik'x'}\left(-[\Pi(x), \Pi(x')] + i\omega[\Pi(x), \varphi(x')] + i\omega[\varphi(x), \Pi(x')] + \omega^{2}[\varphi(x), \varphi(x')]\right) \\
  & = \int \int d^{3}x\, d^{3}x' e^{-ikx}e^{-ik'x'}\left(i\omega(i\delta(x - x')) - i\omega(i\delta(x' - x)\right) \\
  \Aboxed{[a(\bm{k}), a(\bm{k'})] & = 0}\, .
\end{align*}

\begin{align*}
  [a^{\dagger}(\bm{k}), a^{\dagger}(\bm{k'})] & = a^{\dagger}(\bm{k})a^{\dagger}(\bm{k'}) - a^{\dagger}(\bm{k'})a^{\dagger}(\bm{k}) \\
  & = \left(a(\bm{k'})a(\bm{k})\right)^{\dagger} - \left(a(\bm{k})a(\bm{k'})\right)^{\dagger} \\
  & = \left([a(\bm{k'}), a(\bm{k})]\right)^{\dagger} \\
  \Aboxed{[a^{\dagger}(\bm{k}), a^{\dagger}(\bm{k'})] & = 0} \\
\end{align*}

\begin{align*}
  [a(\bm{k}), a^{\dagger}(\bm{k'})] & = \left[\int d^{3}xe^{-ikx}(i\partial_{0}\varphi(x) + \omega\varphi(x)), \int d^{3}x'e^{ik'x'}(-i\partial_{0}\varphi(x') + \omega\varphi(x'))\right] \\
  & = \int \int d^{3}x\, d^{3}x' e^{-ikx}e^{ik'x'}\left[i\partial_{0}\varphi(x) + \omega\varphi(x), -i\partial_{0}\varphi(x') + \omega\varphi(x')\right] \\
  & = \int \int d^{3}x\, d^{3}x' e^{-ikx}e^{ik'x'}\left(-i\cdot i[\Pi(x), \Pi(x')] + i\omega[\Pi(x),\varphi(x')] -i\omega[\varphi(x),\Pi(x')] + \omega^{2}[\varphi(x),\varphi(x')]\right) \\
  & = i\omega\int \int d^{3}x\, d^{3}x' e^{-ikx}e^{ik'x'}\left([\Pi(x),\varphi(x')] -[\varphi(x),\Pi(x')]\right) \\
  & = i\omega\int \int d^{3}x\, d^{3}x' e^{-ikx}e^{ik'x'}\left(-2i\delta(x - x')\right) \\
  & = 2\omega\int d^{3}x\, e^{-i(k' - k)x} \\
  \Aboxed{[a(\bm{k}), a^{\dagger}(\bm{k'})] & = (2\pi)^{3}\,2\omega\,\delta^{3}(k - k')}\, .
\end{align*}

\textit{Srednicki 3.5: a) In eq 3.37, show that $\varphi$ obeys the KG equation.}

This is done by showing that when the variation of the action using this new Lagrangian density is zero, we return two new KG equations; one in $\varphi$ and one in $\varphi^{\dagger}$. However, since this action using lagrangian densities does follow a similar path to the usual functional action, we can use an analogue of the Euler-Lagrange equation for densities to skip having to actually compute the variation. Explicitly, we use
\[ \frac{\partial \mathcal{L}}{\partial \varphi} = \partial_{\mu}\left(\frac{\partial \mathcal{L}}{\partial (\partial_{\mu}\varphi)}\right)\, .
\]

Then, computing each component:

\begin{center}
  $\begin{array}{ c c }
    \frac{\partial \mathcal{L}}{\partial \varphi} = -m^{2}\varphi^{\dagger} & \frac{\partial \mathcal{L}}{\partial \varphi^{\dagger}} = -m^{2}\varphi \\
    \frac{\partial \mathcal{L}}{\partial (\partial_{\mu}\varphi)} = -\partial^{\mu}\varphi^{\dagger} & \frac{\partial \mathcal{L}}{\partial (\partial_{\mu}\varphi^{\dagger})} = -\partial^{\mu}\varphi
  \end{array}$
\end{center}

and combining using the ELE, we get our two equations:
\[ \partial_{\mu}\partial^{\mu}\varphi - m^{2}\varphi = 0 \hspace{2em} \partial_{\mu}\partial^{\mu}\varphi^{\dagger} - m^{2}\varphi^{\dagger} = 0\, , \]
thus indeed $\varphi$ obeys the KG equation.

\textit{b) Treat $\phi$ and $\phi^{\dagger}$ as independent fields and find the conjugate momentum for each. Compute the hamiltonian density in terms of these conjugate momenta and the fields themselves.}

Notice,
\[
p_{1} = \frac{\partial \mathcal{L}}{\partial \dot{\varphi}} = -\dot{\varphi}^{\dagger} \hspace{2em} p_{2} = \frac{\partial \mathcal{L}}{\partial \dot{\varphi}^{\dagger}} = -\dot{\varphi}
\]
are our conjugate momenta, and thus,
\[
\boxed{\mathcal{H} = p_{2}\dot{\varphi}^{\dagger} + p_{1}\dot{\varphi} - \mathcal{L} = -p_{1}p_{2} - p_{2}p_{1} - \mathcal{L}} \, .
\]

\textit{c) Express $a(\bm{k})$ and $b(\bm{k})$ in terms of the fields and their time derivatives.}

To do this, we need to first write out $\varphi$ and $\varphi^{\dagger}$ in $a(\bm{k})$ and $b(\bm{k})$. Try this with $\varphi$,
\begin{align*}
  \int d^{3}x\, e^{-ik'x}\varphi(x) & = \int d^{3}x\, e^{-ik'x}\left(\int d\tilde{k}\left(a(\bm{k})e^{ikx} + b^{\dagger}(\bm{k})e^{-ikx}\right)\right) \\
  & = \int d^{3}x\, e^{-ik'x}\left(\int \frac{d^{3}k}{(2\pi)^{3}2\omega}\left(a(\bm{k})e^{ikx} + b^{\dagger}(\bm{k})e^{-ikx}\right)\right) \\
  & = \int \frac{d^{3}k}{(2\pi)^{3}2\omega}\left(a(\bm{k})\int d^{3}x\,e^{-i(k' - k)x} + b^{\dagger}(\bm{k})\int d^{3}x\,e^{-i(k' + k)x}\right) \\
  & = \int \frac{d^{3}k}{(2\pi)^{3}2\omega}\left(a(\bm{k})(2\pi)^{3}\delta^{3}(k' - k) + b^{\dagger}(\bm{k})(2\pi)^{3}\delta(k + k')e^{2i\omega t}\right) \\
  \Aboxed{\int d^{3}x\, e^{-ik'x}\varphi(x) & = \frac{1}{2\omega}a(\bm{k'}) + \frac{e^{2i\omega t}}{2\omega}b^{\dagger}(-\bm{k'})} \,. 
\end{align*}
Fortunately, we can play this game on the time derivative term aswell as the conjugates and get the following results:
\begin{align}
  \int d^{3}x\, e^{-ikx}\varphi(x) & = \frac{1}{2\omega}a(\bm{k}) + \frac{e^{2i\omega t}}{2\omega}b^{\dagger}(-\bm{k}) \\
  \int d^{3}x\, e^{-ikx}\partial_{0}\varphi(x) & = -\frac{i}{2\omega}a(\bm{k}) + \frac{ie^{2i\omega t}}{2\omega}b^{\dagger}(-\bm{k}) \\
  \int d^{3}x\, e^{-ikx}\varphi(x)^{\dagger} & = \frac{1}{2\omega}b(\bm{k}) + \frac{e^{2i\omega t}}{2\omega}a^{\dagger}(-\bm{k}) \\
  \int d^{3}x\, e^{-ikx}\partial_{0}\varphi(x)^{\dagger} & = -\frac{i}{2\omega}b(\bm{k}) + \frac{ie^{2i\omega t}}{2\omega}a^{\dagger}(-\bm{k}) \, .
\end{align}
Now, to get the equations for $a(\bm{k})$ and $b(\bm{k})$ we need only combine these above equations in useful manners. In particular:
\[
a(\bm{k}) = (\text{1}) + \frac{i}{\omega}(\text{2}) = \int d^{3}x\, \omega e^{-ikx}\left(\varphi + \frac{i}{\omega}\partial_{0}\varphi\right)\, ,
\]
\[
b(\bm{k}) = (\text{3}) + \frac{i}{\omega}(\text{4}) = \int d^{3}x\, \omega e^{-ikx}\left(\varphi^{\dagger} + \frac{i}{\omega}\partial_{0}\varphi^{\dagger}\right)
\]
as required.

\textit{5.1: Work out the LSZ reduction formula for the complex scalar field that was introduced in the previous problem. The type of incoming and outgoing particle must be specified.}

We can follow along with the method used in the text, but now have to consider the extra particle. In particular,
\begin{align*}
  a_{1}^{\dagger}(+\infty) - a_{1}^{\dagger}(-\infty) & = \int_{-\infty}^{\infty}dt\, \partial_{0}a_{1}^{\dagger}(t) \\
  & = \int_{-\infty}^{\infty}dt\, \partial_{0}\left(\int d^{3}k\, f_{1}(\bm{k})a^{\dagger}(\bm{k})\right) \\
  & = \int_{-\infty}^{\infty}dt\, \partial_{0}\left(\int d^{3}k\, f_{1}(\bm{k})\left(\int d^{3}x\, \omega e^{-ikx}\left(\varphi + \frac{i}{\omega}\partial_{0}\varphi\right)\right)\right) \\
  & = -i\int d^{3}k\, f_{1}(\bm{k})\int d^{4}xe^{-ikx}\left(-\partial^{2} + m^{2}\right)\phi^{\dagger}(x) \, .
\end{align*}
Similarly, we can get
\[ a_{1}(\infty) - a_{1}(-\infty) = i\int d^{3}k\, f_{1}(k)\int d^{4}x\, e^{-ikx}\left(-\partial^{2} + m^{2}\right)\phi(x)\, , \]
\[ b_{1}^{\dagger}(\infty) - b_{1}^{\dagger}(-\infty) = -i\int d^{3}k\, f_{1}(k)\int d^{4}x\, e^{-ikx}\left(-\partial^{2} + m^{2}\right)\phi(x)\, , \]
\[ b_{1}(\infty) - b_{1}(-\infty) = i\int d^{3}k\, f_{1}(k)\int d^{4}x\, e^{-ikx}\left(-\partial^{2} + m^{2}\right)\phi^{\dagger}(x)\, . \]
Suppose we have $m + n$ incoming particles, with $m$ of them being $b$ and the other $n$ being $a$. We can use a similar notation for the outgoing particles (now with labels primed) to get the following
\[ \ket{i} = \lim_{t\to -\infty}a_{1}^{\dagger}(t)a_{2}^{\dagger}(t)\cdots a_{n}^{\dagger}(t)b_{1}^{\dagger}(t)\cdots b_{m}^{\dagger}(t)\ket{0}\, , \]
\[ \ket{f} = \lim_{t\to \infty}a_{1}^{\dagger}(t)a_{2}^{\dagger}(t)\cdots a_{n'}^{\dagger}(t)b_{1}^{\dagger}(t)\cdots b_{m'}^{\dagger}(t)\ket{0}\, . \]
Then since only two commutators are non-zero ($[a,a^{\dagger}]$, $[b,b^{\dagger}]$), when we take our overlap and send the raising operators to the left and the lowering to the right we only need to consider these exchanges. We see
\[ \braket{f|i} = \bra{0}Ta_{1}(\infty)a_{2}(\infty)\cdots a_{n'}(\infty)b_{1}(\infty)\cdots b_{m'}(\infty)a_{1}^{\dagger}(-\infty)a_{2}^{\dagger}(-\infty)\cdots a_{n}^{\dagger}(-\infty)b_{1}^{\dagger}(-\infty)\cdots b_{m}^{\dagger}(-\infty)\ket{0}\, . \]
Note that we can compare with the result in Sredniki to get the form of the final result:
\[
\braket{f|i} = i^{m+n+m'+n'}\prod_{i=1}^{n'}\int d^{4}x_{i}e^{-ik_{i}x_{i}}(-\partial_{i}^{2} - m_{a}^{2})\prod_{j=1}^{m'}\int d^{4}x_{j}e^{-ik_{j}x_{j}}(-\partial_{j}^{2} - m^{2})
\]
\[\times\prod_{i'=1}^{n}\int d^{4}x_{i'}e^{ik_{i'}x_{i'}}(-\partial_{i'}^{2} - m_{a}^{2})\prod_{j'=1}^{m}\int d^{4}x_{j'}e^{ik_{j'}x_{j'}}(-\partial_{j'}^{2} - m_{b}^{2})
\]
\[
\times \bra{0}T\prod_{i}^{n'}\varphi(x_{i})\prod_{j}^{m'}\varphi^{\dagger}(x_{j})\prod_{i'}^{n}\varphi(x_{i'})\prod_{j'}^{m}\varphi(x_{j'})\ket{0}\, ,
\]
as required.

\end{document}
