\documentclass[10pt]{article}
\usepackage[]{ragged2e}
\usepackage{fancyhdr,amsmath,amsthm,amssymb,bbm,braket}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper,left=25mm,right=25mm]{geometry}

\setlength{\parskip}{1em}
\setlength{\parindent}{0em}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Sp}{\mathbb{S}}
\newcommand{\Pro}{\mathbb{P}}
\newcommand{\di}[2][]{\frac{\partial #1}{\partial #2}}
\newcommand{\del}[2][]{\frac{d #1}{d #2}}

\DeclareMathOperator{\Ima}{Im}

\linespread{1.25}
\pagestyle{fancy}
\fancyhf{}
\lhead{PHYS 467 $|$  Assignment 1}

%\rhead{Dilraj Ghuman $|$ 20564228}

\begin{document}
\textbf{Question 1}

\textbf{(a)} We know where the basis vectors are being sent under this map, so we know exactly how this matrix should look. Specifically, since we know that basis vectors just pull out coloumns of matrices, we see that the coloumns of the matrix should be the output vectors. Thus,

\[ U =
\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  0 & 1 & 0 & 0 \\
  0 & 0 & 0 & 1 \\
  0 & 0 & 1 & 0 \\
\end{bmatrix}
\hspace{2em} \& \hspace{2em} V =
\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  0 & 0 & 1 & 0 \\
  0 & 1 & 0 & 0 \\
  0 & 0 & 0 & 1 \\
\end{bmatrix}.
\]
The braket notation will look like
\[ U = \ket{00}\bra{00} + \ket{01}\bra{01} + \ket{11}\bra{10} + \ket{10}\bra{11} \hspace{1em} \& \hspace{1em} V = \ket{00}\bra{00} + \ket{10}\bra{01} + \ket{01}\bra{10} + \ket{11}\bra{11} \]
as required.

\textbf{(b)} We first note that $V$ is symmetric and real valued, also known as hermitian, thus $V^{\dagger} = V$. The actions are
\[ \ket{00} \to \ket{00} \hspace{1em} \ket{01} \to \ket{11} \hspace{1em} \ket{10} \to \ket{10} \hspace{1em} \ket{11} \to \ket{01} \hspace{1em} \]
which tells us that the matrix representation better be
\[ VUV^{\dagger} =
\begin{bmatrix}
  1 & 0 & 0 & 0 \\
  0 & 0 & 0 & 1 \\
  0 & 0 & 1 & 0 \\
  0 & 1 & 0 & 0 \\
\end{bmatrix}.
\]
The braket notation will look like
\[ VUV^{\dagger} = \ket{00}\bra{00} + \ket{11}\bra{01} + \ket{10}\bra{10} + \ket{10}\bra{11} \]
as required.

\textbf{(c)} If we call $I$ the identity matrix in $\C^{2}$, we are asked to find $T = H \otimes I$. To get the matrix representation, we first notice that
\[ H\ket{0} = \frac{1}{\sqrt{2}}\ket{0} + \frac{1}{\sqrt{2}}\ket{1} \hspace{2em} H\ket{1} = \frac{1}{\sqrt{2}}\ket{0} - \frac{1}{\sqrt{2}}\ket{1}.\]
With this information, we can get the matrix representation to be
\[ T = \frac{1}{\sqrt{2}}
\begin{bmatrix}
  1 & 0 & 1 & 0 \\
  0 & 1 & 0 & 1 \\
  1 & 0 & -1 & 0 \\
  0 & 1 & 0 & -1 \\
\end{bmatrix}.
\]

For $UT$, we get an action of
\[ \ket{00} \to \frac{1}{\sqrt{2}}(\ket{00}+\ket{11}) \hspace{1em} \ket{01} \to \frac{1}{\sqrt{2}}(\ket{01}+\ket{10}) \]
\[ \ket{10} \to \frac{1}{\sqrt{2}}(\ket{00}-\ket{11}) \hspace{1em} \ket{11} \to \frac{1}{\sqrt{2}}(\ket{01}-\ket{10})\]
and a basis representation of
\[ UT = \frac{1}{\sqrt{2}}
\begin{bmatrix}
  1 & 0 & 1 & 0 \\
  0 & 1 & 0 & 1 \\
  0 & 1 & 0 & -1 \\
  1 & 0 & -1 & 0 \\
\end{bmatrix}
\]
as required.

\newpage
\textbf{Question 2}

\textbf{(a)} This is proven as a direct computation and application of the multilinearity of the tensor. Notice
\[ (M\otimes I)\ket{\Phi} = (M\otimes I)\frac{1}{\sqrt{d}}\sum_{n=0}^{d}\ket{nn} = \frac{1}{\sqrt{d}}(M\otimes I)\sum_{n=0}^{d}(\ket{n}\otimes\ket{n}) = \frac{1}{\sqrt{d}}\sum_{n=0}^{d}(M\ket{n}\otimes I\ket{n})\]
but since the kets $\ket{n}$ form the basis for $M$, $\exists a_{ij}$ such that $M = \sum_{ij=0}^{d}a_{ij}\ket{i}\bra{j}$. Thus
\[ (M\otimes I)\ket{\Phi} = \frac{1}{\sqrt{d}}\sum_{n=0}^{d}\left(\sum_{i,j=0}^{d}a_{ij}\ket{i}\braket{j|n} \otimes \ket{n} \right) = \frac{1}{\sqrt{d}}\sum_{n=0}^{d}\left(\sum_{i=0}^{d}a_{in}\ket{i} \otimes \ket{n} \right).\]
Applying the multilinearity of the tensor, we can move the sums around \textit{and} the coefficient $a_{in}$, so
\[ (M\otimes I)\ket{\Phi} = \frac{1}{\sqrt{d}}\sum_{i=0}^{d}\left(\sum_{n=0}^{d}\ket{i} \otimes a_{in}\ket{n} \right) = \frac{1}{\sqrt{d}}\sum_{i=0}^{d}\left(\sum_{n,m=0}^{d}\ket{i} \otimes a_{mn}\ket{n}\braket{m|i} \right)\]
\[ = \frac{1}{\sqrt{d}}\sum_{i=0}^{d}\left(\sum_{n,m=0}^{d}\ket{i} \otimes a_{mn}\ket{n}\braket{m|i} \right) = \frac{1}{\sqrt{d}} \sum_{i=0}^{d}(I\ket{i} \otimes M^{T}\ket{i})\]
\[ = \frac{1}{\sqrt{d}}(I\otimes M^{T})\sum_{i=0}^{d}(\ket{i}\otimes\ket{i}) = (I\otimes M^{T})\ket{\Phi} \]
as required.

\newpage
\textbf{Question 3}

\textbf{(a)} We know that the probabilities under a complete von Neumann measurement along the basis will simply give the basis vectors each with a probability given by the coefficient of the state. That is,
\[ Prob(\ket{00}) = |a|^{2} \quad Prob(\ket{01}) = |b|^{2} \quad Prob(\ket{10}) = |c|^{2} \quad Prob(\ket{11}) = |d|^{2} \, .\]

\textbf{(b)} (i) We see that the projectors better just be the projectors in the qubit that Alice is using, and then leave Bob's qubit untouched. So,
\[ P_{\ket{0}_{A}} = \ket{0}\bra{0} \otimes I \quad \& \quad P_{\ket{1}_{A}} = \ket{1}\bra{1} \otimes I \]
where we know $I = \ket{0}\bra{0} + \ket{1}\bra{1}$.

(ii) We expect the probability of measuring a ``0'' and ``1'' to be
\[ ||P_{\ket{0}_{A}}\ket{\psi}||_{2}^{2} = ||a\ket{00} + b\ket{01}||^{2}_{2} = |a|^{2} + |b|^{2} \quad \& \quad
||P_{\ket{1}_{A}}\ket{\psi}||_{2}^{2} = ||c\ket{10} + d\ket{11}||^{2}_{2} = |c|^{2} + |d|^{2}\]
respectively. The post measurement states better be
\[ \ket{\psi}_{\ket{0}_{A}} = \frac{1}{\sqrt{|a|^{2} + |b|^{2}}}\left(a\ket{00} + b\ket{01}\right) \quad \& \quad \ket{\psi}_{\ket{1}_{A}} = \frac{1}{\sqrt{|c|^{2} + |d|^{2}}}\left(c\ket{10} + d\ket{11}\right) \]
respectively.

(iii) First, we suppose the measurement outcome $\ket{\psi}_{\ket{0}_{A}}$. Then, we get the probability of a ``0'' and ``1'' to be
\[ ||P_{\ket{0}_{B}}\ket{\psi}_{\ket{0}_{A}}||_{2}^{2} = \frac{1}{|a|^{2}+|b|^{2}}||a\ket{00}||_{2}^{2} = \frac{|a|^{2}}{|a|^{2}+|b|^{2}} \quad \& \quad ||P_{\ket{1}_{B}}\ket{psi}_{\ket{0}_{A}}||_{2}^{2} = \frac{1}{|a|^{2}+|b|^{2}}||b\ket{01}||_{2}^{2} = \frac{|b|^{2}}{|a|^{2}+|b|^{2}}\]
respectively. That is
\[\text{Prob}(\ket{0}_{B}|\ket{0}_{A}) = \frac{|a|^{2}}{|a|^{2}+|b|^{2}} \quad \text{Prob}(\ket{1}_{B}|\ket{0}_{A}) = \frac{|b|^{2}}{|a|^{2}+|b|^{2}} \, .\]
In a similar way, if we suppose the measurement outcome $\ket{\psi}_{\ket{1}_{A}}$, then the probabilities of ``0'' and ``1'' measured by Bob will be
\[\text{Prob}(\ket{0}_{B}|\ket{1}_{A}) = \frac{|c|^{2}}{|c|^{2}+|d|^{2}} \quad \text{Prob}(\ket{1}_{B}|\ket{1}_{A}) = \frac{|d|^{2}}{|c|^{2}+|d|^{2}} \, .\]
To see the joint probability, we recall the definition of conditional probabilities to be
\[ \text{Prob}(A | B) = \frac{\text{Prob}(A)\cap \text{Prob}(B)}{\text{Prob}(B)}\, , \]
so we see that the joint probabilities will be
\[ \text{Prob}(\ket{00}) = \text{Prob}(\ket{0}_{B}|\ket{0}_{A})\cdot \text{Prob}(\ket{0}_{A}) = \frac{|a|^{2}}{|a|^{2} + |b|^{2}}\left(|a|^{2} + |b|^{2}\right) = |a|^{2}\]

\[ \text{Prob}(\ket{01}) = \text{Prob}(\ket{1}_{B}|\ket{0}_{A})\cdot \text{Prob}(\ket{0}_{A}) = \frac{|b|^{2}}{|a|^{2} + |b|^{2}}\left(|a|^{2} + |b|^{2}\right) = |b|^{2}\]

\[ \text{Prob}(\ket{10}) = \text{Prob}(\ket{0}_{B}|\ket{1}_{A})\cdot \text{Prob}(\ket{1}_{A}) = \frac{|c|^{2}}{|c|^{2} + |d|^{2}}\left(|c|^{2} + |d|^{2}\right) = |c|^{2}\]

\[ \text{Prob}(\ket{11}) = \text{Prob}(\ket{1}_{B}|\ket{1}_{A})\cdot \text{Prob}(\ket{1}_{A}) = \frac{|d|^{2}}{|c|^{2} + |d|^{2}}\left(|c|^{2} + |d|^{2}\right) = |d|^{2} \, .\]
We notice all the joint probabilities agree with what we computed in \textbf{(a)}.

\textbf{(c)} We know a similar conclusion would hold for Bob in the computations done in \textbf{(b)} since the measurements done by each person only affects their individual qubit. For this reason, whether we check on Bob first or Alice first will not change the calculation. From a purely mathematical perspective, the projection operator that applies the measurement only applies to one of the qubits, and is tensored to an identity for the other qubit.

\textbf{(d)} To begin with, we would suppose two bases, one for Alice and one for Bob which they will use to measure their qubit. We would then build a new basis, which would be the joint basis for the $\ket{\psi}$ state that is defined by the tensor of the two bases defined by Alice and Bob. This new basis would give the joint probability for each outcome once the initial ket is rewritten in this basis. Then, as we did above, we would measure along the basis for Alice, and get the probabilities as measure by her, and then measure along Bob's basis for each of Alice's outcomes.

We know this would hold for an arbitrary basis, because each of Alice and Bob's basis better be two vectors, and the inner product will be difined. That is, changing how we look at the state does not change the actual state.

\newpage
\textbf{Question 4}

\textbf{(a)} To see this, we note the following products,
\[ TM_{+} = T\left(\frac{I + T}{2}\right) = \frac{1}{2}\left(T + T^{2}\right) = \frac{T + I}{2} = M_{+} \]
\[ TM_{-} = T\left(\frac{I - T}{2}\right) = \frac{1}{2}\left(T - T^{2}\right) = \frac{T - I}{2} = -M_{+} \, .\]
From the definition of matrix multiplication, we see that the coloumns of $M_{+}$ better span the $+1$ eignspace, and similarly the coloumns of $M_{-}$ better span the $-1$ eigenspace of $T$. Thus, from the definition of projectors, $M_{+}$ and $M_{-}$ better project onto the $+1$ and $-1$ eigenspace respectively.

\textbf{(b)} (i) We know that the eigenvalues of a tensor of operators better be the product of the eigenvalues. Since both $S_{1}$ and $S_{2}$ carry eigenvalues of $\pm 1$, we can expect the eigenvalues of $S_{1}\otimes S_{2}$ also be $\pm 1$.

(ii) For the four possible joint outcomes, (+1,+1), (+1,-1), (-1,+1), (-1,-1), we have the following projectors:
\[ P_{++} = \left(\frac{I + S_{1}}{2}\right)\otimes \left(\frac{I+S_{2}}{2}\right) \quad
P_{+-} = \left(\frac{I + S_{1}}{2}\right)\otimes \left(\frac{I - S_{2}}{2}\right) \] 
\[ P_{-+} = \left(\frac{I - S_{1}}{2}\right)\otimes \left(\frac{I + S_{2}}{2}\right) \quad
P_{--} = \left(\frac{I - S_{1}}{2}\right)\otimes \left(\frac{I - S_{2}}{2}\right)\]
respectively.

(iii) Intuitively, we know that only the (+1,+1) and (-1,-1) outcomes will have positive probabilities since they corrspond with +1 eigenstates in the $S$ measurement, since the eigenvalue is found by taking the product of the eigenvalues.

To see that this is true explicitly, we just show that the complementary outcomes, (-1,+1) and (+1,-1) have no probability of occuring. To see this, we use the projectors we built before, that is
\[ P_{+-}\ket{\psi} = \left(\frac{I + S_{1}}{2}\right)\otimes \left(\frac{I - S_{2}}{2}\right)\ket{\psi} = \frac{1}{4}\left(I\otimes I - I\otimes S_{2} + S_{1}\otimes I - S\right)\ket{\psi} \]
\[= \frac{1}{4}\left(\ket{\psi} + \left(S_{1}\otimes I - I\otimes S_{2}\right)\ket{\psi} - S\ket{\psi}\right) = \frac{1}{4}\left(S_{1}\otimes I - I\otimes S_{2}\right)\ket{\psi}\, .\]
To continue, we notice that we need to confirm how $\ket{\psi}$ interacts with the systems $S_{1}$ and $S_{2}$ that are tensored with the identity. Notice, we can assume $\sum_{i=1,j=1}^{d_{1},d_{2}}c_{i,j}\ket{i}\otimes \ket{j} = \ket{\psi}$ where $\{\ket{i}\}$ and $\{\ket{j}\}$ span the spaces that $S_{1}$ and $S_{2}$ act on respectively, and $\sum_{i=1,j=1}^{d_{1},d_{2}}c_{ij} = 1$. Then,
\[ \ket{\psi} = S\ket{\psi} = (S_{1}\otimes S_{2})\sum_{i=1,j=1}^{d_{1},d_{2}}c_{i,j}\ket{i}\otimes \ket{j} = \sum_{i=1,j=1}^{d_{1},d_{2}}c_{i,j}(S_{1}\ket{i}\otimes S_{2}\ket{j})\]
\[ \implies S_{1}\ket{i} = \pm\ket{i} \quad \& \quad S_{2}\ket{j} = \pm\ket{j} \, .\]
This tells us that the $\ket{\psi}$ better decompose into the product state of two kets that form the eigenspaces of the same eigenvalue (either both +1 or both -1). With this, we see that the calculation we left undone vanishes, since
\[ (S_{1}\otimes I)\ket{\psi} = (I\otimes S_{2})\ket{\psi} \implies P_{+-}\ket{\psi} = 0 \, .\]
Similarily, we would get the same expansion for $P_{-+}$, since we only flip a negative in each. So, since both projectors give the zero vector, we expect to only get a probability of zero. Then, we know that the only outcomes with positive probability will be (+1,+1) and (-1,-1).

(iv) We approach this exactly as we did in (iii), but flip the projector we use. Notice, in this case we get that
\[ (S_{1}\otimes I)\ket{\psi} = -(I\otimes S_{2})\ket{\psi} \]
due to the flipped eigenvalues. Then, we can again show that the probability for the complementary outcome is zero,
\[ P_{++}\ket{\psi} = \frac{1}{4}(I + S_{1})\otimes(I + S_{2})\ket{\psi} = \frac{1}{4}\left(I\otimes I + I\otimes S_{2} + S_{1}\otimes I + S\right)\ket{\psi} = 0 \]
and similarly for $P_{--}$. Thus, we have that the complementary outcomes better be the outcomes with positive probability.

\end{document}
